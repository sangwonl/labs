{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6389825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "# Constants\n",
    "GRID_SIZE = 5\n",
    "CELL_SIZE = 100\n",
    "FPS = 4\n",
    "\n",
    "# Colors\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "RED = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "\n",
    "# Actions\n",
    "LEFT = 0\n",
    "RIGHT = 1\n",
    "UP = 2\n",
    "DOWN = 3\n",
    "\n",
    "# Phase\n",
    "PHASE_GO = 'go'\n",
    "PHASE_RETURN = 'return'\n",
    "\n",
    "# Rewards\n",
    "STEP_REWARD = -1\n",
    "GOAL_REWARD = 10\n",
    "RETURN_REWARD = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6ead72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HomeMazeEnv(gym.Env):\n",
    "    def __init__(self, grid_size=GRID_SIZE):\n",
    "        super(HomeMazeEnv, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.start_pos = (0, 0)\n",
    "        self.goal_pos = (grid_size - 1, grid_size - 1)\n",
    "        self.current_pos = self.start_pos\n",
    "        self.phase = PHASE_GO\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0, 0], dtype=np.int32),\n",
    "            high=np.array([grid_size - 1, grid_size - 1], dtype=np.int32),\n",
    "            dtype=np.int32)\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_pos = self.start_pos\n",
    "        self.phase = PHASE_GO\n",
    "        return np.array(self.current_pos, dtype=np.int32), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.current_pos\n",
    "        if action == LEFT: x = max(0, x - 1)\n",
    "        elif action == RIGHT: x = min(self.grid_size - 1, x + 1)\n",
    "        elif action == UP: y = max(0, y - 1)\n",
    "        elif action == DOWN: y = min(self.grid_size - 1, y + 1)\n",
    "        self.current_pos = (x, y)\n",
    "\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        reward = STEP_REWARD\n",
    "\n",
    "        if self.phase == PHASE_GO and self.current_pos == self.goal_pos:\n",
    "            self.phase = PHASE_RETURN\n",
    "            reward = GOAL_REWARD\n",
    "        elif self.phase == PHASE_RETURN and self.current_pos == self.start_pos:\n",
    "            reward = RETURN_REWARD\n",
    "            terminated = True\n",
    "\n",
    "        return np.array(self.current_pos, dtype=np.int32), reward, terminated, truncated, {}\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19cc9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 235      |\n",
      "|    ep_rew_mean     | -203     |\n",
      "| time/              |          |\n",
      "|    fps             | 9001     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 267         |\n",
      "|    ep_rew_mean          | -235        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 5943        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 0           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008908768 |\n",
      "|    clip_fraction        | 0.0452      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.000682    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 293         |\n",
      "|    ep_rew_mean          | -261        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 5465        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010554854 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.0648     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 371         |\n",
      "|    ep_rew_mean          | -339        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 5080        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008552227 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.0665     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 369          |\n",
      "|    ep_rew_mean          | -337         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 5010         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072560133 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -0.0148      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.6         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 376          |\n",
      "|    ep_rew_mean          | -344         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4940         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053049745 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | -0.0053      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.5         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    value_loss           | 112          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 375         |\n",
      "|    ep_rew_mean          | -343        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4896        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005004257 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -0.0036     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.000517   |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 341          |\n",
      "|    ep_rew_mean          | -309         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4864         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063336575 |\n",
      "|    clip_fraction        | 0.0573       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | -0.00126     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 43.2         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | -317        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4855        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008854795 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.000513   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 360          |\n",
      "|    ep_rew_mean          | -328         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4848         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023417494 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | -0.000251    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00012     |\n",
      "|    value_loss           | 94.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 407          |\n",
      "|    ep_rew_mean          | -375         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4838         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049266517 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | -0.000216    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.6         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 73.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 407         |\n",
      "|    ep_rew_mean          | -375        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4834        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006540018 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.000152   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    value_loss           | 71.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 407          |\n",
      "|    ep_rew_mean          | -375         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4800         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052779582 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.00102      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0944       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000448    |\n",
      "|    value_loss           | 10.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 407         |\n",
      "|    ep_rew_mean          | -375        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4761        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009515075 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.000567    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.217       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    value_loss           | 6.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 407         |\n",
      "|    ep_rew_mean          | -375        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4731        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006570965 |\n",
      "|    clip_fraction        | 0.0317      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -0.00289    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00748     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 3.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 575         |\n",
      "|    ep_rew_mean          | -543        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4728        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007496001 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | -0.000851   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0436      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.000852   |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 596          |\n",
      "|    ep_rew_mean          | -564         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4711         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051489836 |\n",
      "|    clip_fraction        | 0.0255       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | -7.52e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 103          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 53           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 601          |\n",
      "|    ep_rew_mean          | -569         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4674         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036820546 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -7.15e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 104          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 600          |\n",
      "|    ep_rew_mean          | -568         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4684         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058805905 |\n",
      "|    clip_fraction        | 0.0611       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -4.42e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.3         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0073      |\n",
      "|    value_loss           | 98.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 577          |\n",
      "|    ep_rew_mean          | -545         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4676         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035388013 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -2.13e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 268          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000841    |\n",
      "|    value_loss           | 203          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 553          |\n",
      "|    ep_rew_mean          | -521         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 4659         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025629937 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | -1.68e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 415          |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.000651    |\n",
      "|    value_loss           | 324          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | -507        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4660        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002668724 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -1.05e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.000489   |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 531         |\n",
      "|    ep_rew_mean          | -499        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4667        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003858537 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -6.79e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    value_loss           | 288         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 528         |\n",
      "|    ep_rew_mean          | -496        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4673        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007840755 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -5.6e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | -505        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 4666        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004036602 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | -5.13e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.000347   |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "Model saved to models/ppo_maze.zip\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 모델을 저장할 디렉토리 생성\n",
    "models_dir = \"models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "env = HomeMazeEnv(grid_size=GRID_SIZE)\n",
    "check_env(env)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=50000)\n",
    "# model.learn(total_timesteps=500)\n",
    "\n",
    "# 학습된 모델 저장\n",
    "model_path = os.path.join(models_dir, \"ppo_maze\")\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}.zip\")\n",
    "\n",
    "# 모델 로드 테스트 (선택사항)\n",
    "loaded_model = PPO.load(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f61bf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "class HomeMazeGameEnv:\n",
    "    def __init__(self, grid_size=GRID_SIZE, cell_size=CELL_SIZE):\n",
    "        self.grid_size = grid_size\n",
    "        self.cell_size = cell_size\n",
    "        self.window_size = grid_size * cell_size\n",
    "\n",
    "        self.start_pos = (0, 0)\n",
    "        self.goal_pos = (grid_size - 1, grid_size - 1)\n",
    "        self.current_pos = self.start_pos\n",
    "        self.phase = 'go'\n",
    "\n",
    "        pygame.init()\n",
    "        pygame.display.init()\n",
    "        self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "    def _create_grid_surface(self):\n",
    "        surface = pygame.Surface((self.window_size, self.window_size))\n",
    "        surface.fill(WHITE)\n",
    "\n",
    "        # Draw grid lines\n",
    "        for i in range(self.grid_size + 1):\n",
    "            pygame.draw.line(surface, BLACK, (i * self.cell_size, 0),\n",
    "                            (i * self.cell_size, self.window_size), 2)\n",
    "            pygame.draw.line(surface, BLACK, (0, i * self.cell_size),\n",
    "                            (self.window_size, i * self.cell_size), 2)\n",
    "        return surface\n",
    "\n",
    "    def _draw_position(self, surface, pos, color, is_circle=False):\n",
    "        x, y = pos\n",
    "        if is_circle:\n",
    "            pygame.draw.circle(\n",
    "                surface,\n",
    "                color,\n",
    "                (x * self.cell_size + self.cell_size // 2,\n",
    "                 y * self.cell_size + self.cell_size // 2),\n",
    "                self.cell_size // 3\n",
    "            )\n",
    "        else:\n",
    "            pygame.draw.rect(\n",
    "                surface,\n",
    "                color,\n",
    "                pygame.Rect(\n",
    "                    x * self.cell_size,\n",
    "                    y * self.cell_size,\n",
    "                    self.cell_size,\n",
    "                    self.cell_size\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_pos = self.start_pos\n",
    "        self.phase = 'go'\n",
    "        self._render_frame()\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.current_pos\n",
    "        if action == LEFT: x = max(0, x - 1)\n",
    "        elif action == RIGHT: x = min(self.grid_size - 1, x + 1)\n",
    "        elif action == UP: y = max(0, y - 1)\n",
    "        elif action == DOWN: y = min(self.grid_size - 1, y + 1)\n",
    "        self.current_pos = (x, y)\n",
    "\n",
    "        done = False\n",
    "\n",
    "        if self.phase == 'go' and self.current_pos == self.goal_pos:\n",
    "            self.phase = 'return'\n",
    "        elif self.phase == 'return' and self.current_pos == self.start_pos:\n",
    "            done = True\n",
    "\n",
    "        self._render_frame()\n",
    "        return done\n",
    "\n",
    "    def _render_frame(self):\n",
    "        # Create base grid\n",
    "        canvas = self._create_grid_surface()\n",
    "\n",
    "        # Draw positions\n",
    "        self._draw_position(canvas, self.start_pos, GREEN)\n",
    "        self._draw_position(canvas, self.goal_pos, RED)\n",
    "        self._draw_position(canvas, self.current_pos, BLUE, is_circle=True)\n",
    "\n",
    "        self.window.blit(canvas, canvas.get_rect())\n",
    "        pygame.event.pump()\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(FPS)\n",
    "\n",
    "    def close(self):\n",
    "        if self.window is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75fe191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 12:58:57.854 python[97748:31632205] +[IMKClient subclass]: chose IMKClient_Modern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "귀소 실패!\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "env = HomeMazeGameEnv()\n",
    "model = PPO.load(\"models/ppo_maze\")\n",
    "\n",
    "env.reset()\n",
    "for step in range(20):\n",
    "    obs = np.array(env.current_pos, dtype=np.int32)\n",
    "    action, _states = model.predict(obs)\n",
    "    terminated = env.step(action)\n",
    "\n",
    "    if step == 0:\n",
    "        sleep(4)\n",
    "\n",
    "    if terminated:\n",
    "        print(\"귀소 성공!\")\n",
    "        break\n",
    "else:\n",
    "    print(\"귀소 실패!\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e48e7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
